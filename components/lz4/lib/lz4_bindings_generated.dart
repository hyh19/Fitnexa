// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// Bindings for `src/lz4.h`.
///
/// Regenerate bindings with `flutter pub run ffigen --config ffigen.yaml`.
///
class Lz4Bindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  Lz4Bindings(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  Lz4Bindings.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  int LZ4_versionNumber() {
    return _LZ4_versionNumber();
  }

  late final _LZ4_versionNumberPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('LZ4_versionNumber');
  late final _LZ4_versionNumber =
      _LZ4_versionNumberPtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Char> LZ4_versionString() {
    return _LZ4_versionString();
  }

  late final _LZ4_versionStringPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'LZ4_versionString');
  late final _LZ4_versionString =
      _LZ4_versionStringPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// -************************************
  /// Simple Functions
  /// /
  /// /*! LZ4_compress_default() :
  /// Compresses 'srcSize' bytes from buffer 'src'
  /// into already allocated 'dst' buffer of size 'dstCapacity'.
  /// Compression is guaranteed to succeed if 'dstCapacity' >= LZ4_compressBound(srcSize).
  /// It also runs faster, so it's a recommended setting.
  /// If the function cannot compress 'src' into a more limited 'dst' budget,
  /// compression stops *immediately*, and the function result is zero.
  /// In which case, 'dst' content is undefined (invalid).
  /// srcSize : max supported value is LZ4_MAX_INPUT_SIZE.
  /// dstCapacity : size of buffer 'dst' (which must be already allocated)
  /// @return  : the number of bytes written into buffer 'dst' (necessarily <= dstCapacity)
  /// or 0 if compression fails
  /// Note : This function is protected against buffer overflow scenarios (never writes outside 'dst' buffer, nor read outside 'source' buffer).
  int LZ4_compress_default(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
  ) {
    return _LZ4_compress_default(
      src,
      dst,
      srcSize,
      dstCapacity,
    );
  }

  late final _LZ4_compress_defaultPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int)>>('LZ4_compress_default');
  late final _LZ4_compress_default = _LZ4_compress_defaultPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int)>();

  /// ! LZ4_decompress_safe() :
  /// @compressedSize : is the exact complete size of the compressed block.
  /// @dstCapacity : is the size of destination buffer (which must be already allocated),
  /// is an upper bound of decompressed size.
  /// @return : the number of bytes decompressed into destination buffer (necessarily <= dstCapacity)
  /// If destination buffer is not large enough, decoding will stop and output an error code (negative value).
  /// If the source stream is detected malformed, the function will stop decoding and return a negative result.
  /// Note 1 : This function is protected against malicious data packets :
  /// it will never writes outside 'dst' buffer, nor read outside 'source' buffer,
  /// even if the compressed block is maliciously modified to order the decoder to do these actions.
  /// In such case, the decoder stops immediately, and considers the compressed block malformed.
  /// Note 2 : compressedSize and dstCapacity must be provided to the function, the compressed block does not contain them.
  /// The implementation is free to send / store / derive this information in whichever way is most beneficial.
  /// If there is a need for a different format which bundles together both compressed data and its metadata, consider looking at lz4frame.h instead.
  int LZ4_decompress_safe(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int compressedSize,
    int dstCapacity,
  ) {
    return _LZ4_decompress_safe(
      src,
      dst,
      compressedSize,
      dstCapacity,
    );
  }

  late final _LZ4_decompress_safePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int)>>('LZ4_decompress_safe');
  late final _LZ4_decompress_safe = _LZ4_decompress_safePtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int)>();

  /// ! LZ4_compressBound() :
  /// Provides the maximum size that LZ4 compression may output in a "worst case" scenario (input data not compressible)
  /// This function is primarily useful for memory allocation purposes (destination buffer size).
  /// Macro LZ4_COMPRESSBOUND() is also provided for compilation-time evaluation (stack memory allocation for example).
  /// Note that LZ4_compress_default() compresses faster when dstCapacity is >= LZ4_compressBound(srcSize)
  /// inputSize  : max supported value is LZ4_MAX_INPUT_SIZE
  /// return : maximum output size in a "worst case" scenario
  /// or 0, if input size is incorrect (too large or negative)
  int LZ4_compressBound(
    int inputSize,
  ) {
    return _LZ4_compressBound(
      inputSize,
    );
  }

  late final _LZ4_compressBoundPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'LZ4_compressBound');
  late final _LZ4_compressBound =
      _LZ4_compressBoundPtr.asFunction<int Function(int)>();

  /// ! LZ4_compress_fast() :
  /// Same as LZ4_compress_default(), but allows selection of "acceleration" factor.
  /// The larger the acceleration value, the faster the algorithm, but also the lesser the compression.
  /// It's a trade-off. It can be fine tuned, with each successive value providing roughly +~3% to speed.
  /// An acceleration value of "1" is the same as regular LZ4_compress_default()
  /// Values <= 0 will be replaced by LZ4_ACCELERATION_DEFAULT (currently == 1, see lz4.c).
  /// Values > LZ4_ACCELERATION_MAX will be replaced by LZ4_ACCELERATION_MAX (currently == 65537, see lz4.c).
  int LZ4_compress_fast(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
    int acceleration,
  ) {
    return _LZ4_compress_fast(
      src,
      dst,
      srcSize,
      dstCapacity,
      acceleration,
    );
  }

  late final _LZ4_compress_fastPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int, ffi.Int)>>('LZ4_compress_fast');
  late final _LZ4_compress_fast = _LZ4_compress_fastPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int, int)>();

  /// ! LZ4_compress_fast_extState() :
  /// Same as LZ4_compress_fast(), using an externally allocated memory space for its state.
  /// Use LZ4_sizeofState() to know how much memory must be allocated,
  /// and allocate it on 8-bytes boundaries (using `malloc()` typically).
  /// Then, provide this buffer as `void* state` to compression function.
  int LZ4_sizeofState() {
    return _LZ4_sizeofState();
  }

  late final _LZ4_sizeofStatePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('LZ4_sizeofState');
  late final _LZ4_sizeofState =
      _LZ4_sizeofStatePtr.asFunction<int Function()>();

  int LZ4_compress_fast_extState(
    ffi.Pointer<ffi.Void> state,
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
    int acceleration,
  ) {
    return _LZ4_compress_fast_extState(
      state,
      src,
      dst,
      srcSize,
      dstCapacity,
      acceleration,
    );
  }

  late final _LZ4_compress_fast_extStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('LZ4_compress_fast_extState');
  late final _LZ4_compress_fast_extState =
      _LZ4_compress_fast_extStatePtr.asFunction<
          int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int, int, int)>();

  /// ! LZ4_compress_destSize() :
  /// Reverse the logic : compresses as much data as possible from 'src' buffer
  /// into already allocated buffer 'dst', of size >= 'targetDestSize'.
  /// This function either compresses the entire 'src' content into 'dst' if it's large enough,
  /// or fill 'dst' buffer completely with as much data as possible from 'src'.
  /// note: acceleration parameter is fixed to "default".
  ///
  /// *srcSizePtr : will be modified to indicate how many bytes where read from 'src' to fill 'dst'.
  /// New value is necessarily <= input value.
  /// @return : Nb bytes written into 'dst' (necessarily <= targetDestSize)
  /// or 0 if compression fails.
  ///
  /// Note : from v1.8.2 to v1.9.1, this function had a bug (fixed un v1.9.2+):
  /// the produced compressed content could, in specific circumstances,
  /// require to be decompressed into a destination buffer larger
  /// by at least 1 byte than the content to decompress.
  /// If an application uses `LZ4_compress_destSize()`,
  /// it's highly recommended to update liblz4 to v1.9.2 or better.
  /// If this can't be done or ensured,
  /// the receiving decompression function should provide
  /// a dstCapacity which is > decompressedSize, by at least 1 byte.
  /// See https://github.com/lz4/lz4/issues/859 for details
  int LZ4_compress_destSize(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    ffi.Pointer<ffi.Int> srcSizePtr,
    int targetDstSize,
  ) {
    return _LZ4_compress_destSize(
      src,
      dst,
      srcSizePtr,
      targetDstSize,
    );
  }

  late final _LZ4_compress_destSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Int>, ffi.Int)>>('LZ4_compress_destSize');
  late final _LZ4_compress_destSize = _LZ4_compress_destSizePtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Int>, int)>();

  /// ! LZ4_decompress_safe_partial() :
  /// Decompress an LZ4 compressed block, of size 'srcSize' at position 'src',
  /// into destination buffer 'dst' of size 'dstCapacity'.
  /// Up to 'targetOutputSize' bytes will be decoded.
  /// The function stops decoding on reaching this objective.
  /// This can be useful to boost performance
  /// whenever only the beginning of a block is required.
  ///
  /// @return : the number of bytes decoded in `dst` (necessarily <= targetOutputSize)
  /// If source stream is detected malformed, function returns a negative result.
  ///
  /// Note 1 : @return can be < targetOutputSize, if compressed block contains less data.
  ///
  /// Note 2 : targetOutputSize must be <= dstCapacity
  ///
  /// Note 3 : this function effectively stops decoding on reaching targetOutputSize,
  /// so dstCapacity is kind of redundant.
  /// This is because in older versions of this function,
  /// decoding operation would still write complete sequences.
  /// Therefore, there was no guarantee that it would stop writing at exactly targetOutputSize,
  /// it could write more bytes, though only up to dstCapacity.
  /// Some "margin" used to be required for this operation to work properly.
  /// Thankfully, this is no longer necessary.
  /// The function nonetheless keeps the same signature, in an effort to preserve API compatibility.
  ///
  /// Note 4 : If srcSize is the exact size of the block,
  /// then targetOutputSize can be any value,
  /// including larger than the block's decompressed size.
  /// The function will, at most, generate block's decompressed size.
  ///
  /// Note 5 : If srcSize is _larger_ than block's compressed size,
  /// then targetOutputSize **MUST** be <= block's decompressed size.
  /// Otherwise, *silent corruption will occur*.
  int LZ4_decompress_safe_partial(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int targetOutputSize,
    int dstCapacity,
  ) {
    return _LZ4_decompress_safe_partial(
      src,
      dst,
      srcSize,
      targetOutputSize,
      dstCapacity,
    );
  }

  late final _LZ4_decompress_safe_partialPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int, ffi.Int)>>('LZ4_decompress_safe_partial');
  late final _LZ4_decompress_safe_partial =
      _LZ4_decompress_safe_partialPtr.asFunction<
          int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int, int)>();

  ffi.Pointer<LZ4_stream_t> LZ4_createStream() {
    return _LZ4_createStream();
  }

  late final _LZ4_createStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<LZ4_stream_t> Function()>>(
          'LZ4_createStream');
  late final _LZ4_createStream =
      _LZ4_createStreamPtr.asFunction<ffi.Pointer<LZ4_stream_t> Function()>();

  int LZ4_freeStream(
    ffi.Pointer<LZ4_stream_t> streamPtr,
  ) {
    return _LZ4_freeStream(
      streamPtr,
    );
  }

  late final _LZ4_freeStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<LZ4_stream_t>)>>(
          'LZ4_freeStream');
  late final _LZ4_freeStream =
      _LZ4_freeStreamPtr.asFunction<int Function(ffi.Pointer<LZ4_stream_t>)>();

  /// ! LZ4_resetStream_fast() : v1.9.0+
  /// Use this to prepare an LZ4_stream_t for a new chain of dependent blocks
  /// (e.g., LZ4_compress_fast_continue()).
  ///
  /// An LZ4_stream_t must be initialized once before usage.
  /// This is automatically done when created by LZ4_createStream().
  /// However, should the LZ4_stream_t be simply declared on stack (for example),
  /// it's necessary to initialize it first, using LZ4_initStream().
  ///
  /// After init, start any new stream with LZ4_resetStream_fast().
  /// A same LZ4_stream_t can be re-used multiple times consecutively
  /// and compress multiple streams,
  /// provided that it starts each new stream with LZ4_resetStream_fast().
  ///
  /// LZ4_resetStream_fast() is much faster than LZ4_initStream(),
  /// but is not compatible with memory regions containing garbage data.
  ///
  /// Note: it's only useful to call LZ4_resetStream_fast()
  /// in the context of streaming compression.
  /// The *extState* functions perform their own resets.
  /// Invoking LZ4_resetStream_fast() before is redundant, and even counterproductive.
  void LZ4_resetStream_fast(
    ffi.Pointer<LZ4_stream_t> streamPtr,
  ) {
    return _LZ4_resetStream_fast(
      streamPtr,
    );
  }

  late final _LZ4_resetStream_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<LZ4_stream_t>)>>(
          'LZ4_resetStream_fast');
  late final _LZ4_resetStream_fast = _LZ4_resetStream_fastPtr.asFunction<
      void Function(ffi.Pointer<LZ4_stream_t>)>();

  /// ! LZ4_loadDict() :
  /// Use this function to reference a static dictionary into LZ4_stream_t.
  /// The dictionary must remain available during compression.
  /// LZ4_loadDict() triggers a reset, so any previous data will be forgotten.
  /// The same dictionary will have to be loaded on decompression side for successful decoding.
  /// Dictionary are useful for better compression of small data (KB range).
  /// While LZ4 accept any input as dictionary,
  /// results are generally better when using Zstandard's Dictionary Builder.
  /// Loading a size of 0 is allowed, and is the same as reset.
  /// @return : loaded dictionary size, in bytes (necessarily <= 64 KB)
  int LZ4_loadDict(
    ffi.Pointer<LZ4_stream_t> streamPtr,
    ffi.Pointer<ffi.Char> dictionary,
    int dictSize,
  ) {
    return _LZ4_loadDict(
      streamPtr,
      dictionary,
      dictSize,
    );
  }

  late final _LZ4_loadDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_loadDict');
  late final _LZ4_loadDict = _LZ4_loadDictPtr.asFunction<
      int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>, int)>();

  /// ! LZ4_compress_fast_continue() :
  /// Compress 'src' content using data from previously compressed blocks, for better compression ratio.
  /// 'dst' buffer must be already allocated.
  /// If dstCapacity >= LZ4_compressBound(srcSize), compression is guaranteed to succeed, and runs faster.
  ///
  /// @return : size of compressed block
  /// or 0 if there is an error (typically, cannot fit into 'dst').
  ///
  /// Note 1 : Each invocation to LZ4_compress_fast_continue() generates a new block.
  /// Each block has precise boundaries.
  /// Each block must be decompressed separately, calling LZ4_decompress_*() with relevant metadata.
  /// It's not possible to append blocks together and expect a single invocation of LZ4_decompress_*() to decompress them together.
  ///
  /// Note 2 : The previous 64KB of source data is __assumed__ to remain present, unmodified, at same address in memory !
  ///
  /// Note 3 : When input is structured as a double-buffer, each buffer can have any size, including < 64 KB.
  /// Make sure that buffers are separated, by at least one byte.
  /// This construction ensures that each block only depends on previous block.
  ///
  /// Note 4 : If input buffer is a ring-buffer, it can have any size, including < 64 KB.
  ///
  /// Note 5 : After an error, the stream status is undefined (invalid), it can only be reset or freed.
  int LZ4_compress_fast_continue(
    ffi.Pointer<LZ4_stream_t> streamPtr,
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
    int acceleration,
  ) {
    return _LZ4_compress_fast_continue(
      streamPtr,
      src,
      dst,
      srcSize,
      dstCapacity,
      acceleration,
    );
  }

  late final _LZ4_compress_fast_continuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<LZ4_stream_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('LZ4_compress_fast_continue');
  late final _LZ4_compress_fast_continue =
      _LZ4_compress_fast_continuePtr.asFunction<
          int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int, int, int)>();

  /// ! LZ4_saveDict() :
  /// If last 64KB data cannot be guaranteed to remain available at its current memory location,
  /// save it into a safer place (char* safeBuffer).
  /// This is schematically equivalent to a memcpy() followed by LZ4_loadDict(),
  /// but is much faster, because LZ4_saveDict() doesn't need to rebuild tables.
  /// @return : saved dictionary size in bytes (necessarily <= maxDictSize), or 0 if error.
  int LZ4_saveDict(
    ffi.Pointer<LZ4_stream_t> streamPtr,
    ffi.Pointer<ffi.Char> safeBuffer,
    int maxDictSize,
  ) {
    return _LZ4_saveDict(
      streamPtr,
      safeBuffer,
      maxDictSize,
    );
  }

  late final _LZ4_saveDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_saveDict');
  late final _LZ4_saveDict = _LZ4_saveDictPtr.asFunction<
      int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>, int)>();

  ffi.Pointer<LZ4_streamDecode_t> LZ4_createStreamDecode() {
    return _LZ4_createStreamDecode();
  }

  late final _LZ4_createStreamDecodePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<LZ4_streamDecode_t> Function()>>(
          'LZ4_createStreamDecode');
  late final _LZ4_createStreamDecode = _LZ4_createStreamDecodePtr.asFunction<
      ffi.Pointer<LZ4_streamDecode_t> Function()>();

  int LZ4_freeStreamDecode(
    ffi.Pointer<LZ4_streamDecode_t> LZ4_stream,
  ) {
    return _LZ4_freeStreamDecode(
      LZ4_stream,
    );
  }

  late final _LZ4_freeStreamDecodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<LZ4_streamDecode_t>)>>('LZ4_freeStreamDecode');
  late final _LZ4_freeStreamDecode = _LZ4_freeStreamDecodePtr.asFunction<
      int Function(ffi.Pointer<LZ4_streamDecode_t>)>();

  /// ! LZ4_setStreamDecode() :
  /// An LZ4_streamDecode_t context can be allocated once and re-used multiple times.
  /// Use this function to start decompression of a new stream of blocks.
  /// A dictionary can optionally be set. Use NULL or size 0 for a reset order.
  /// Dictionary is presumed stable : it must remain accessible and unmodified during next decompression.
  /// @return : 1 if OK, 0 if error
  int LZ4_setStreamDecode(
    ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
    ffi.Pointer<ffi.Char> dictionary,
    int dictSize,
  ) {
    return _LZ4_setStreamDecode(
      LZ4_streamDecode,
      dictionary,
      dictSize,
    );
  }

  late final _LZ4_setStreamDecodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<LZ4_streamDecode_t>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('LZ4_setStreamDecode');
  late final _LZ4_setStreamDecode = _LZ4_setStreamDecodePtr.asFunction<
      int Function(
          ffi.Pointer<LZ4_streamDecode_t>, ffi.Pointer<ffi.Char>, int)>();

  /// ! LZ4_decoderRingBufferSize() : v1.8.2+
  /// Note : in a ring buffer scenario (optional),
  /// blocks are presumed decompressed next to each other
  /// up to the moment there is not enough remaining space for next block (remainingSize < maxBlockSize),
  /// at which stage it resumes from beginning of ring buffer.
  /// When setting such a ring buffer for streaming decompression,
  /// provides the minimum size of this ring buffer
  /// to be compatible with any source respecting maxBlockSize condition.
  /// @return : minimum ring buffer size,
  /// or 0 if there is an error (invalid maxBlockSize).
  int LZ4_decoderRingBufferSize(
    int maxBlockSize,
  ) {
    return _LZ4_decoderRingBufferSize(
      maxBlockSize,
    );
  }

  late final _LZ4_decoderRingBufferSizePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'LZ4_decoderRingBufferSize');
  late final _LZ4_decoderRingBufferSize =
      _LZ4_decoderRingBufferSizePtr.asFunction<int Function(int)>();

  /// ! LZ4_decompress_safe_continue() :
  /// This decoding function allows decompression of consecutive blocks in "streaming" mode.
  /// The difference with the usual independent blocks is that
  /// new blocks are allowed to find references into former blocks.
  /// A block is an unsplittable entity, and must be presented entirely to the decompression function.
  /// LZ4_decompress_safe_continue() only accepts one block at a time.
  /// It's modeled after `LZ4_decompress_safe()` and behaves similarly.
  ///
  /// @LZ4_streamDecode : decompression state, tracking the position in memory of past data
  /// @compressedSize : exact complete size of one compressed block.
  /// @dstCapacity : size of destination buffer (which must be already allocated),
  /// must be an upper bound of decompressed size.
  /// @return : number of bytes decompressed into destination buffer (necessarily <= dstCapacity)
  /// If destination buffer is not large enough, decoding will stop and output an error code (negative value).
  /// If the source stream is detected malformed, the function will stop decoding and return a negative result.
  ///
  /// The last 64KB of previously decoded data *must* remain available and unmodified
  /// at the memory position where they were previously decoded.
  /// If less than 64KB of data has been decoded, all the data must be present.
  ///
  /// Special : if decompression side sets a ring buffer, it must respect one of the following conditions :
  /// - Decompression buffer size is _at least_ LZ4_decoderRingBufferSize(maxBlockSize).
  /// maxBlockSize is the maximum size of any single block. It can have any value > 16 bytes.
  /// In which case, encoding and decoding buffers do not need to be synchronized.
  /// Actually, data can be produced by any source compliant with LZ4 format specification, and respecting maxBlockSize.
  /// - Synchronized mode :
  /// Decompression buffer size is _exactly_ the same as compression buffer size,
  /// and follows exactly same update rule (block boundaries at same positions),
  /// and decoding function is provided with exact decompressed size of each block (exception for last block of the stream),
  /// _then_ decoding & encoding ring buffer can have any size, including small ones ( < 64 KB).
  /// - Decompression buffer is larger than encoding buffer, by a minimum of maxBlockSize more bytes.
  /// In which case, encoding and decoding buffers do not need to be synchronized,
  /// and encoding ring buffer can have any size, including small ones ( < 64 KB).
  ///
  /// Whenever these conditions are not possible,
  /// save the last 64KB of decoded data into a safe buffer where it can't be modified during decompression,
  /// then indicate where this data is saved using LZ4_setStreamDecode(), before decompressing next block.
  int LZ4_decompress_safe_continue(
    ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
  ) {
    return _LZ4_decompress_safe_continue(
      LZ4_streamDecode,
      src,
      dst,
      srcSize,
      dstCapacity,
    );
  }

  late final _LZ4_decompress_safe_continuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<LZ4_streamDecode_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int)>>('LZ4_decompress_safe_continue');
  late final _LZ4_decompress_safe_continue =
      _LZ4_decompress_safe_continuePtr.asFunction<
          int Function(ffi.Pointer<LZ4_streamDecode_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int, int)>();

  /// ! LZ4_decompress_safe_usingDict() :
  /// Works the same as
  /// a combination of LZ4_setStreamDecode() followed by LZ4_decompress_safe_continue()
  /// However, it's stateless: it doesn't need any LZ4_streamDecode_t state.
  /// Dictionary is presumed stable : it must remain accessible and unmodified during decompression.
  /// Performance tip : Decompression speed can be substantially increased
  /// when dst == dictStart + dictSize.
  int LZ4_decompress_safe_usingDict(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int srcSize,
    int dstCapacity,
    ffi.Pointer<ffi.Char> dictStart,
    int dictSize,
  ) {
    return _LZ4_decompress_safe_usingDict(
      src,
      dst,
      srcSize,
      dstCapacity,
      dictStart,
      dictSize,
    );
  }

  late final _LZ4_decompress_safe_usingDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_safe_usingDict');
  late final _LZ4_decompress_safe_usingDict =
      _LZ4_decompress_safe_usingDictPtr.asFunction<
          int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// ! LZ4_decompress_safe_partial_usingDict() :
  /// Behaves the same as LZ4_decompress_safe_partial()
  /// with the added ability to specify a memory segment for past data.
  /// Performance tip : Decompression speed can be substantially increased
  /// when dst == dictStart + dictSize.
  int LZ4_decompress_safe_partial_usingDict(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int compressedSize,
    int targetOutputSize,
    int maxOutputSize,
    ffi.Pointer<ffi.Char> dictStart,
    int dictSize,
  ) {
    return _LZ4_decompress_safe_partial_usingDict(
      src,
      dst,
      compressedSize,
      targetOutputSize,
      maxOutputSize,
      dictStart,
      dictSize,
    );
  }

  late final _LZ4_decompress_safe_partial_usingDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_safe_partial_usingDict');
  late final _LZ4_decompress_safe_partial_usingDict =
      _LZ4_decompress_safe_partial_usingDictPtr.asFunction<
          int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int,
              int, ffi.Pointer<ffi.Char>, int)>();

  /// ! LZ4_initStream() : v1.9.0+
  /// An LZ4_stream_t structure must be initialized at least once.
  /// This is automatically done when invoking LZ4_createStream(),
  /// but it's not when the structure is simply declared on stack (for example).
  ///
  /// Use LZ4_initStream() to properly initialize a newly declared LZ4_stream_t.
  /// It can also initialize any arbitrary buffer of sufficient size,
  /// and will @return a pointer of proper type upon initialization.
  ///
  /// Note : initialization fails if size and alignment conditions are not respected.
  /// In which case, the function will @return NULL.
  /// Note2: An LZ4_stream_t structure guarantees correct alignment and size.
  /// Note3: Before v1.9.0, use LZ4_resetStream() instead
  ffi.Pointer<LZ4_stream_t> LZ4_initStream(
    ffi.Pointer<ffi.Void> buffer,
    int size,
  ) {
    return _LZ4_initStream(
      buffer,
      size,
    );
  }

  late final _LZ4_initStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<LZ4_stream_t> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('LZ4_initStream');
  late final _LZ4_initStream = _LZ4_initStreamPtr.asFunction<
      ffi.Pointer<LZ4_stream_t> Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! Obsolete compression functions (since v1.7.3)
  int LZ4_compress(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dest,
    int srcSize,
  ) {
    return _LZ4_compress(
      src,
      dest,
      srcSize,
    );
  }

  late final _LZ4_compressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_compress');
  late final _LZ4_compress = _LZ4_compressPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int LZ4_compress_limitedOutput(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dest,
    int srcSize,
    int maxOutputSize,
  ) {
    return _LZ4_compress_limitedOutput(
      src,
      dest,
      srcSize,
      maxOutputSize,
    );
  }

  late final _LZ4_compress_limitedOutputPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int)>>('LZ4_compress_limitedOutput');
  late final _LZ4_compress_limitedOutput =
      _LZ4_compress_limitedOutputPtr.asFunction<
          int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int)>();

  int LZ4_compress_withState(
    ffi.Pointer<ffi.Void> state,
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int inputSize,
  ) {
    return _LZ4_compress_withState(
      state,
      source,
      dest,
      inputSize,
    );
  }

  late final _LZ4_compress_withStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('LZ4_compress_withState');
  late final _LZ4_compress_withState = _LZ4_compress_withStatePtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, int)>();

  int LZ4_compress_limitedOutput_withState(
    ffi.Pointer<ffi.Void> state,
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int inputSize,
    int maxOutputSize,
  ) {
    return _LZ4_compress_limitedOutput_withState(
      state,
      source,
      dest,
      inputSize,
      maxOutputSize,
    );
  }

  late final _LZ4_compress_limitedOutput_withStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int)>>('LZ4_compress_limitedOutput_withState');
  late final _LZ4_compress_limitedOutput_withState =
      _LZ4_compress_limitedOutput_withStatePtr.asFunction<
          int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int, int)>();

  int LZ4_compress_continue(
    ffi.Pointer<LZ4_stream_t> LZ4_streamPtr,
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int inputSize,
  ) {
    return _LZ4_compress_continue(
      LZ4_streamPtr,
      source,
      dest,
      inputSize,
    );
  }

  late final _LZ4_compress_continuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('LZ4_compress_continue');
  late final _LZ4_compress_continue = _LZ4_compress_continuePtr.asFunction<
      int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, int)>();

  int LZ4_compress_limitedOutput_continue(
    ffi.Pointer<LZ4_stream_t> LZ4_streamPtr,
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int inputSize,
    int maxOutputSize,
  ) {
    return _LZ4_compress_limitedOutput_continue(
      LZ4_streamPtr,
      source,
      dest,
      inputSize,
      maxOutputSize,
    );
  }

  late final _LZ4_compress_limitedOutput_continuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<LZ4_stream_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int)>>('LZ4_compress_limitedOutput_continue');
  late final _LZ4_compress_limitedOutput_continue =
      _LZ4_compress_limitedOutput_continuePtr.asFunction<
          int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int, int)>();

  /// ! Obsolete decompression functions (since v1.8.0)
  int LZ4_uncompress(
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int outputSize,
  ) {
    return _LZ4_uncompress(
      source,
      dest,
      outputSize,
    );
  }

  late final _LZ4_uncompressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_uncompress');
  late final _LZ4_uncompress = _LZ4_uncompressPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int LZ4_uncompress_unknownOutputSize(
    ffi.Pointer<ffi.Char> source,
    ffi.Pointer<ffi.Char> dest,
    int isize,
    int maxOutputSize,
  ) {
    return _LZ4_uncompress_unknownOutputSize(
      source,
      dest,
      isize,
      maxOutputSize,
    );
  }

  late final _LZ4_uncompress_unknownOutputSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int)>>('LZ4_uncompress_unknownOutputSize');
  late final _LZ4_uncompress_unknownOutputSize =
      _LZ4_uncompress_unknownOutputSizePtr.asFunction<
          int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int)>();

  /// Obsolete streaming functions (since v1.7.0)
  /// degraded functionality; do not use!
  ///
  /// In order to perform streaming compression, these functions depended on data
  /// that is no longer tracked in the state. They have been preserved as well as
  /// possible: using them will still produce a correct output. However, they don't
  /// actually retain any history between compression calls. The compression ratio
  /// achieved will therefore be no better than compressing each chunk
  /// independently.
  ffi.Pointer<ffi.Void> LZ4_create(
    ffi.Pointer<ffi.Char> inputBuffer,
  ) {
    return _LZ4_create(
      inputBuffer,
    );
  }

  late final _LZ4_createPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Char>)>>('LZ4_create');
  late final _LZ4_create = _LZ4_createPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Char>)>();

  int LZ4_sizeofStreamState() {
    return _LZ4_sizeofStreamState();
  }

  late final _LZ4_sizeofStreamStatePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('LZ4_sizeofStreamState');
  late final _LZ4_sizeofStreamState =
      _LZ4_sizeofStreamStatePtr.asFunction<int Function()>();

  int LZ4_resetStreamState(
    ffi.Pointer<ffi.Void> state,
    ffi.Pointer<ffi.Char> inputBuffer,
  ) {
    return _LZ4_resetStreamState(
      state,
      inputBuffer,
    );
  }

  late final _LZ4_resetStreamStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Char>)>>('LZ4_resetStreamState');
  late final _LZ4_resetStreamState = _LZ4_resetStreamStatePtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> LZ4_slideInputBuffer(
    ffi.Pointer<ffi.Void> state,
  ) {
    return _LZ4_slideInputBuffer(
      state,
    );
  }

  late final _LZ4_slideInputBufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Void>)>>('LZ4_slideInputBuffer');
  late final _LZ4_slideInputBuffer = _LZ4_slideInputBufferPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Void>)>();

  /// ! Obsolete streaming decoding functions (since v1.7.0)
  int LZ4_decompress_safe_withPrefix64k(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int compressedSize,
    int maxDstSize,
  ) {
    return _LZ4_decompress_safe_withPrefix64k(
      src,
      dst,
      compressedSize,
      maxDstSize,
    );
  }

  late final _LZ4_decompress_safe_withPrefix64kPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int, ffi.Int)>>('LZ4_decompress_safe_withPrefix64k');
  late final _LZ4_decompress_safe_withPrefix64k =
      _LZ4_decompress_safe_withPrefix64kPtr.asFunction<
          int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int, int)>();

  int LZ4_decompress_fast_withPrefix64k(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int originalSize,
  ) {
    return _LZ4_decompress_fast_withPrefix64k(
      src,
      dst,
      originalSize,
    );
  }

  late final _LZ4_decompress_fast_withPrefix64kPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_fast_withPrefix64k');
  late final _LZ4_decompress_fast_withPrefix64k =
      _LZ4_decompress_fast_withPrefix64kPtr.asFunction<
          int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  /// ! Obsolete LZ4_decompress_fast variants (since v1.9.0) :
  /// These functions used to be faster than LZ4_decompress_safe(),
  /// but this is no longer the case. They are now slower.
  /// This is because LZ4_decompress_fast() doesn't know the input size,
  /// and therefore must progress more cautiously into the input buffer to not read beyond the end of block.
  /// On top of that `LZ4_decompress_fast()` is not protected vs malformed or malicious inputs, making it a security liability.
  /// As a consequence, LZ4_decompress_fast() is strongly discouraged, and deprecated.
  ///
  /// The last remaining LZ4_decompress_fast() specificity is that
  /// it can decompress a block without knowing its compressed size.
  /// Such functionality can be achieved in a more secure manner
  /// by employing LZ4_decompress_safe_partial().
  ///
  /// Parameters:
  /// originalSize : is the uncompressed size to regenerate.
  /// `dst` must be already allocated, its size must be >= 'originalSize' bytes.
  /// @return : number of bytes read from source buffer (== compressed size).
  /// The function expects to finish at block's end exactly.
  /// If the source stream is detected malformed, the function stops decoding and returns a negative result.
  /// note : LZ4_decompress_fast*() requires originalSize. Thanks to this information, it never writes past the output buffer.
  /// However, since it doesn't know its 'src' size, it may read an unknown amount of input, past input buffer bounds.
  /// Also, since match offsets are not validated, match reads from 'src' may underflow too.
  /// These issues never happen if input (compressed) data is correct.
  /// But they may happen if input data is invalid (error or intentional tampering).
  /// As a consequence, use these functions in trusted environments with trusted data **only**.
  int LZ4_decompress_fast(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int originalSize,
  ) {
    return _LZ4_decompress_fast(
      src,
      dst,
      originalSize,
    );
  }

  late final _LZ4_decompress_fastPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_fast');
  late final _LZ4_decompress_fast = _LZ4_decompress_fastPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int LZ4_decompress_fast_continue(
    ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int originalSize,
  ) {
    return _LZ4_decompress_fast_continue(
      LZ4_streamDecode,
      src,
      dst,
      originalSize,
    );
  }

  late final _LZ4_decompress_fast_continuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<LZ4_streamDecode_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_fast_continue');
  late final _LZ4_decompress_fast_continue =
      _LZ4_decompress_fast_continuePtr.asFunction<
          int Function(ffi.Pointer<LZ4_streamDecode_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int)>();

  int LZ4_decompress_fast_usingDict(
    ffi.Pointer<ffi.Char> src,
    ffi.Pointer<ffi.Char> dst,
    int originalSize,
    ffi.Pointer<ffi.Char> dictStart,
    int dictSize,
  ) {
    return _LZ4_decompress_fast_usingDict(
      src,
      dst,
      originalSize,
      dictStart,
      dictSize,
    );
  }

  late final _LZ4_decompress_fast_usingDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('LZ4_decompress_fast_usingDict');
  late final _LZ4_decompress_fast_usingDict =
      _LZ4_decompress_fast_usingDictPtr.asFunction<
          int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// ! LZ4_resetStream() :
  /// An LZ4_stream_t structure must be initialized at least once.
  /// This is done with LZ4_initStream(), or LZ4_resetStream().
  /// Consider switching to LZ4_initStream(),
  /// invoking LZ4_resetStream() will trigger deprecation warnings in the future.
  void LZ4_resetStream(
    ffi.Pointer<LZ4_stream_t> streamPtr,
  ) {
    return _LZ4_resetStream(
      streamPtr,
    );
  }

  late final _LZ4_resetStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<LZ4_stream_t>)>>(
          'LZ4_resetStream');
  late final _LZ4_resetStream = _LZ4_resetStreamPtr.asFunction<
      void Function(ffi.Pointer<LZ4_stream_t>)>();
}

class LZ4_stream_u extends ffi.Union {
  @ffi.Array.multi([16416])
  external ffi.Array<ffi.Char> minStateSize;

  external LZ4_stream_t_internal internal_donotuse;
}

class LZ4_stream_t_internal extends ffi.Struct {
  @ffi.Array.multi([4096])
  external ffi.Array<LZ4_u32> hashTable;

  external ffi.Pointer<LZ4_byte> dictionary;

  external ffi.Pointer<LZ4_stream_t_internal> dictCtx;

  @LZ4_u32()
  external int currentOffset;

  @LZ4_u32()
  external int tableType;

  @LZ4_u32()
  external int dictSize;
}

typedef LZ4_u32 = ffi.Uint32;
typedef LZ4_byte = ffi.Uint8;

/// -*********************************************
/// Streaming Compression Functions
typedef LZ4_stream_t = LZ4_stream_u;

class LZ4_streamDecode_u extends ffi.Union {
  @ffi.Array.multi([32])
  external ffi.Array<ffi.Char> minStateSize;

  external LZ4_streamDecode_t_internal internal_donotuse;
}

/// ! LZ4_streamDecode_t :
/// Never ever use below internal definitions directly !
/// These definitions are not API/ABI safe, and may change in future versions.
/// If you need static allocation, declare or allocate an LZ4_streamDecode_t object.
class LZ4_streamDecode_t_internal extends ffi.Struct {
  external ffi.Pointer<LZ4_byte> externalDict;

  external ffi.Pointer<LZ4_byte> prefixEnd;

  @ffi.Size()
  external int extDictSize;

  @ffi.Size()
  external int prefixSize;
}

/// -**********************************************
/// Streaming Decompression Functions
/// Bufferless synchronous API
typedef LZ4_streamDecode_t = LZ4_streamDecode_u;

const int LZ4_FREESTANDING = 0;

const int LZ4_VERSION_MAJOR = 1;

const int LZ4_VERSION_MINOR = 9;

const int LZ4_VERSION_RELEASE = 4;

const int LZ4_VERSION_NUMBER = 10904;

const String LZ4_VERSION_STRING = '1.9.4';

const int LZ4_MEMORY_USAGE_MIN = 10;

const int LZ4_MEMORY_USAGE_DEFAULT = 14;

const int LZ4_MEMORY_USAGE_MAX = 20;

const int LZ4_MEMORY_USAGE = 14;

const int LZ4_MAX_INPUT_SIZE = 2113929216;

const int LZ4_HASHLOG = 12;

const int LZ4_HASHTABLESIZE = 16384;

const int LZ4_HASH_SIZE_U32 = 4096;

const int LZ4_STREAM_MINSIZE = 16416;

const int LZ4_STREAMDECODE_MINSIZE = 32;
